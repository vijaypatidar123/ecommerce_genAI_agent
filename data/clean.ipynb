{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mxjnR3KMUfA",
        "outputId": "52350c0d-131d-462b-fcd1-4ace4dc4b635"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Cleaning olist_customers_dataset.csv ...\n",
            "Removed 0 duplicates.\n",
            "‚úÖ Cleaned file saved as cleaned_olist_customers_dataset.csv\n",
            "\n",
            "Cleaning olist_orders_dataset.csv ...\n",
            "Removed 0 duplicates.\n",
            "‚úÖ Cleaned file saved as cleaned_olist_orders_dataset.csv\n",
            "\n",
            "Cleaning olist_order_items_dataset.csv ...\n",
            "Removed 0 duplicates.\n",
            "‚úÖ Cleaned file saved as cleaned_olist_order_items_dataset.csv\n",
            "\n",
            "Cleaning olist_order_payments_dataset.csv ...\n",
            "Removed 0 duplicates.\n",
            "‚úÖ Cleaned file saved as cleaned_olist_order_payments_dataset.csv\n",
            "\n",
            "Cleaning olist_order_reviews_dataset.csv ...\n",
            "Removed 0 duplicates.\n",
            "‚úÖ Cleaned file saved as cleaned_olist_order_reviews_dataset.csv\n",
            "\n",
            "Cleaning olist_products_dataset.csv ...\n",
            "Removed 0 duplicates.\n",
            "‚úÖ Cleaned file saved as cleaned_olist_products_dataset.csv\n",
            "\n",
            "Cleaning olist_sellers_dataset.csv ...\n",
            "Removed 0 duplicates.\n",
            "‚úÖ Cleaned file saved as cleaned_olist_sellers_dataset.csv\n",
            "\n",
            "Cleaning product_category_name_translation.csv ...\n",
            "Removed 0 duplicates.\n",
            "‚úÖ Cleaned file saved as cleaned_product_category_name_translation.csv\n",
            "\n",
            "Cleaning olist_geolocation_dataset.csv ...\n",
            "Removed 261831 duplicates.\n",
            "‚úÖ Cleaned file saved as cleaned_olist_geolocation_dataset.csv\n",
            "\n",
            "üéØ All files cleaned and saved in 'clean_data/' directory.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Path where your raw csvs are located\n",
        "RAW_PATH = \"/content\"\n",
        "CLEAN_PATH = \"/content/clean\"\n",
        "os.makedirs(CLEAN_PATH, exist_ok=True)\n",
        "\n",
        "def clean_csv(file_name):\n",
        "    df = pd.read_csv(os.path.join(RAW_PATH, file_name))\n",
        "    print(f\"\\nCleaning {file_name} ...\")\n",
        "\n",
        "    # --- 1Ô∏è‚É£ Standardize column names ---\n",
        "    df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
        "\n",
        "    # --- 2Ô∏è‚É£ Drop duplicates ---\n",
        "    before = len(df)\n",
        "    df = df.drop_duplicates()\n",
        "    print(f\"Removed {before - len(df)} duplicates.\")\n",
        "\n",
        "    # --- 3Ô∏è‚É£ Drop columns with >50% missing values ---\n",
        "    threshold = len(df) * 0.5\n",
        "    df = df.dropna(thresh=threshold, axis=1)\n",
        "\n",
        "    # --- 4Ô∏è‚É£ Fill or drop remaining missing values ---\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == 'O':  # string columns\n",
        "            df[col] = df[col].fillna(\"unknown\")\n",
        "        else:\n",
        "            df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "    # --- 5Ô∏è‚É£ Save cleaned file ---\n",
        "    clean_name = f\"cleaned_{file_name}\"\n",
        "    df.to_csv(os.path.join(CLEAN_PATH, clean_name), index=False)\n",
        "    print(f\"‚úÖ Cleaned file saved as {clean_name}\")\n",
        "\n",
        "# List of dataset files\n",
        "files = [\n",
        "    \"olist_customers_dataset.csv\",\n",
        "    \"olist_orders_dataset.csv\",\n",
        "    \"olist_order_items_dataset.csv\",\n",
        "    \"olist_order_payments_dataset.csv\",\n",
        "    \"olist_order_reviews_dataset.csv\",\n",
        "    \"olist_products_dataset.csv\",\n",
        "    \"olist_sellers_dataset.csv\",\n",
        "    \"product_category_name_translation.csv\",\n",
        "    \"olist_geolocation_dataset.csv\"\n",
        "]\n",
        "\n",
        "for f in files:\n",
        "    clean_csv(f)\n",
        "\n",
        "print(\"\\nüéØ All files cleaned and saved in 'clean_data/' directory.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5yvfKf5NnIp",
        "outputId": "c7e24575-43f7-4636-a770-56e247f47517"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìÇ Analyzing missing values in: olist_customers_dataset.csv\n",
            "Empty DataFrame\n",
            "Columns: [column_name, missing_count, missing_percent, file_name]\n",
            "Index: []\n",
            "\n",
            "üìÇ Analyzing missing values in: olist_orders_dataset.csv\n",
            "                     column_name  missing_count  missing_percent  \\\n",
            "6  order_delivered_customer_date           2965         2.981668   \n",
            "5   order_delivered_carrier_date           1783         1.793023   \n",
            "4              order_approved_at            160         0.160899   \n",
            "\n",
            "                  file_name  \n",
            "6  olist_orders_dataset.csv  \n",
            "5  olist_orders_dataset.csv  \n",
            "4  olist_orders_dataset.csv  \n",
            "\n",
            "üìÇ Analyzing missing values in: olist_order_items_dataset.csv\n",
            "Empty DataFrame\n",
            "Columns: [column_name, missing_count, missing_percent, file_name]\n",
            "Index: []\n",
            "\n",
            "üìÇ Analyzing missing values in: olist_order_payments_dataset.csv\n",
            "Empty DataFrame\n",
            "Columns: [column_name, missing_count, missing_percent, file_name]\n",
            "Index: []\n",
            "\n",
            "üìÇ Analyzing missing values in: olist_order_reviews_dataset.csv\n",
            "              column_name  missing_count  missing_percent  \\\n",
            "3    review_comment_title          87656        88.341530   \n",
            "4  review_comment_message          58247        58.702532   \n",
            "\n",
            "                         file_name  \n",
            "3  olist_order_reviews_dataset.csv  \n",
            "4  olist_order_reviews_dataset.csv  \n",
            "\n",
            "üìÇ Analyzing missing values in: olist_products_dataset.csv\n",
            "                  column_name  missing_count  missing_percent  \\\n",
            "1       product_category_name            610         1.851234   \n",
            "2         product_name_lenght            610         1.851234   \n",
            "3  product_description_lenght            610         1.851234   \n",
            "4          product_photos_qty            610         1.851234   \n",
            "5            product_weight_g              2         0.006070   \n",
            "6           product_length_cm              2         0.006070   \n",
            "7           product_height_cm              2         0.006070   \n",
            "8            product_width_cm              2         0.006070   \n",
            "\n",
            "                    file_name  \n",
            "1  olist_products_dataset.csv  \n",
            "2  olist_products_dataset.csv  \n",
            "3  olist_products_dataset.csv  \n",
            "4  olist_products_dataset.csv  \n",
            "5  olist_products_dataset.csv  \n",
            "6  olist_products_dataset.csv  \n",
            "7  olist_products_dataset.csv  \n",
            "8  olist_products_dataset.csv  \n",
            "\n",
            "üìÇ Analyzing missing values in: olist_sellers_dataset.csv\n",
            "Empty DataFrame\n",
            "Columns: [column_name, missing_count, missing_percent, file_name]\n",
            "Index: []\n",
            "\n",
            "üìÇ Analyzing missing values in: product_category_name_translation.csv\n",
            "Empty DataFrame\n",
            "Columns: [column_name, missing_count, missing_percent, file_name]\n",
            "Index: []\n",
            "\n",
            "üìÇ Analyzing missing values in: olist_geolocation_dataset.csv\n",
            "Empty DataFrame\n",
            "Columns: [column_name, missing_count, missing_percent, file_name]\n",
            "Index: []\n",
            "\n",
            "‚úÖ Missing value report saved to: /content/missing_value_report.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Define your raw data path\n",
        "RAW_PATH = \"/content\"\n",
        "REPORT_PATH = \"/content/missing_value_report.csv\"\n",
        "\n",
        "# List of dataset files\n",
        "files = [\n",
        "    \"olist_customers_dataset.csv\",\n",
        "    \"olist_orders_dataset.csv\",\n",
        "    \"olist_order_items_dataset.csv\",\n",
        "    \"olist_order_payments_dataset.csv\",\n",
        "    \"olist_order_reviews_dataset.csv\",\n",
        "    \"olist_products_dataset.csv\",\n",
        "    \"olist_sellers_dataset.csv\",\n",
        "    \"product_category_name_translation.csv\",\n",
        "    \"olist_geolocation_dataset.csv\"\n",
        "]\n",
        "\n",
        "# Store summary for all files\n",
        "missing_summary = []\n",
        "\n",
        "def analyze_missing_values(file_name):\n",
        "    \"\"\"Analyze missing values in a single CSV file.\"\"\"\n",
        "    file_path = os.path.join(RAW_PATH, file_name)\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"‚ö†Ô∏è File not found: {file_name}\")\n",
        "        return None\n",
        "\n",
        "    print(f\"\\nüìÇ Analyzing missing values in: {file_name}\")\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Calculate missing values\n",
        "    missing_count = df.isnull().sum()\n",
        "    missing_percent = (missing_count / len(df)) * 100\n",
        "\n",
        "    # Create a summary DataFrame for this file\n",
        "    summary = pd.DataFrame({\n",
        "        \"column_name\": df.columns,\n",
        "        \"missing_count\": missing_count.values,\n",
        "        \"missing_percent\": missing_percent.values\n",
        "    })\n",
        "\n",
        "    # Add file name as a column\n",
        "    summary[\"file_name\"] = file_name\n",
        "\n",
        "    # Print top columns with missing data\n",
        "    print(summary[summary[\"missing_count\"] > 0].sort_values(\"missing_percent\", ascending=False).head(10))\n",
        "\n",
        "    return summary\n",
        "\n",
        "# Process all files and collect reports\n",
        "for f in files:\n",
        "    summary = analyze_missing_values(f)\n",
        "    if summary is not None:\n",
        "        missing_summary.append(summary)\n",
        "\n",
        "# Combine all summaries\n",
        "if missing_summary:\n",
        "    final_report = pd.concat(missing_summary, ignore_index=True)\n",
        "    final_report.to_csv(REPORT_PATH, index=False)\n",
        "    print(f\"\\n‚úÖ Missing value report saved to: {REPORT_PATH}\")\n",
        "else:\n",
        "    print(\"\\n‚ùå No valid files found or no missing values detected.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWkrGrxVQytW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.12.6)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
